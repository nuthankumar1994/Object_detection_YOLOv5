{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BauZokomFVM8",
        "outputId": "9032c887-3485-414f-91ce-6039e64fe1d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-20 11:45:46--  https://evp-ml-data.s3.us-east-2.amazonaws.com/ml-interview/openimages-personcar/trainval.tar.gz\n",
            "Resolving evp-ml-data.s3.us-east-2.amazonaws.com (evp-ml-data.s3.us-east-2.amazonaws.com)... 52.219.105.250\n",
            "Connecting to evp-ml-data.s3.us-east-2.amazonaws.com (evp-ml-data.s3.us-east-2.amazonaws.com)|52.219.105.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 734266940 (700M) [application/x-gzip]\n",
            "Saving to: â€˜trainval.tar.gzâ€™\n",
            "\n",
            "trainval.tar.gz     100%[===================>] 700.25M  79.7MB/s    in 9.0s    \n",
            "\n",
            "2022-04-20 11:45:55 (78.0 MB/s) - â€˜trainval.tar.gzâ€™ saved [734266940/734266940]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://evp-ml-data.s3.us-east-2.amazonaws.com/ml-interview/openimages-personcar/trainval.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "file = tarfile.open('/content/trainval.tar.gz')"
      ],
      "metadata": {
        "id": "i2fsAKgYHRJM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file.extractall('/content/Data')"
      ],
      "metadata": {
        "id": "WPULg6ZHLuBX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tfa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "class InputPipeline:\n",
        "    def __init__(self,input_file\n",
        "                 ,width=1024.0\n",
        "                 ,height=1024.0):\n",
        "      \"\"\"\n",
        "      Class to convert format of input images and\n",
        "      bounding boxes to the one supported by YOLOv5.\n",
        "      \"\"\"\n",
        "      self.file = input_file\n",
        "      self.width = width\n",
        "      self.height = height\n",
        "      self._main()\n",
        "\n",
        "    def _load_json(self):      \n",
        "      \"\"\"\n",
        "      Loading the json file for images and bboxes.\n",
        "      \"\"\"\n",
        "      annotate = open(self.file)\n",
        "      annotation_file = json.load(annotate)\n",
        "      return annotation_file\n",
        "    \n",
        "    def _extract_column(self):\n",
        "      \"\"\"\n",
        "      Extract relevant fields from images and annotations\n",
        "      \"\"\"\n",
        "      annotation_file = self._load_json()\n",
        "      images = pd.json_normalize(annotation_file['images'])\n",
        "      boxes = pd.json_normalize(annotation_file['annotations'])\n",
        "      return images, boxes\n",
        "    \n",
        "    def _clean_data(self):\n",
        "      \"\"\"\n",
        "  \t  Dropping irrelevant columns from images and bounding box dataframes\n",
        "      \"\"\"\n",
        "      images, boxes = self._extract_column()\n",
        "      images.drop('license',axis=1,inplace=True)\n",
        "      boxes.drop(['segmentation','license','id','area','iscrowd']\n",
        "                       ,axis=1,inplace=True)\n",
        "      images.rename(columns = {'id':'image_id'}, inplace = True)\n",
        "      return images, boxes\n",
        "      \n",
        "    def _merge_data(self):\n",
        "      \"\"\"\n",
        "      Consolidating image and bounding box dataframes, grouping by image_id field\n",
        "      \"\"\"\n",
        "      images, boxes = self._clean_data()\n",
        "      boxes = boxes.groupby('image_id').\\\n",
        "            aggregate(lambda tdf: tdf.tolist())\n",
        "      final_data = pd.merge(images,boxes,on=\"image_id\")\n",
        "      return final_data\n",
        "    \n",
        "    def _spliting_data(self):\n",
        "      \"\"\"\n",
        "      Splitting data to train and validation subsets\n",
        "      \"\"\"\n",
        "      final_data = self._merge_data()\n",
        "      train_data, test_data = train_test_split(final_data,test_size=0.1,\n",
        "                                         shuffle=True)\n",
        "      train_data.reset_index(drop=True,inplace=True)\n",
        "      test_data.reset_index(drop=True,inplace=True)\n",
        "      return train_data, test_data\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_format_xywh(out):\n",
        "      \"\"\"\n",
        "      Convert bounding box coordinates \n",
        "      (x_upperLeft, y_upperLeft, x_bottomRight, y_bottomRight)\n",
        "      to the format supported by YOLOv5:\n",
        "      (x_center, y_center, width, height)\n",
        "      \"\"\"\n",
        "      return np.stack([\n",
        "        (out[...,0]+out[...,2])/2.0,\n",
        "        (out[...,1]+out[...,3])/2.0,\n",
        "        out[...,2]-out[...,0],\n",
        "        out[...,3]-out[...,1]],axis=-1)\n",
        "       \n",
        "    def _transform(self,data):\n",
        "      \"\"\"\n",
        "      Rescale bounding boxes to (1024, 1024)\n",
        "      and convert bounding boxes to their relative values\n",
        "      \"\"\"\n",
        "      for id,bboxes in enumerate(data.bbox):\n",
        "        for idx,box in enumerate(bboxes):\n",
        "          box.insert(0,(data[\"category_id\"][id][idx]-1))\n",
        "          box[3] = box[3]+box[1]\n",
        "          box[4] = box[4]+box[2]\n",
        "          box[1] = (box[1]*self.width)/data.width[id]\n",
        "          box[2] = (box[2]*self.height)/data.height[id]\n",
        "          box[3] = (box[3]*self.width)/data.width[id]\n",
        "          box[4] = (box[4]*self.height)/data.height[id]\n",
        "          box[1:] = self.convert_format_xywh(np.array(box[1:]))\n",
        "          box[1] = box[1]/self.width\n",
        "          box[2] = box[2]/self.height\n",
        "          box[3] = box[3]/self.width\n",
        "          box[4] = box[4]/self.height\n",
        "    \n",
        "    def _creating_data(self):\n",
        "      \"\"\"\n",
        "      Apply all functions and create updated subsets of data\n",
        "      \"\"\"\n",
        "      train_data, test_data = self._spliting_data()\n",
        "      self._transform(train_data)\n",
        "      self._transform(test_data)\n",
        "      return train_data, test_data\n",
        "    \n",
        "    @staticmethod\n",
        "    def _make_dir(path):\n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    def _saving_images_labels(self,data,choose_train_val=\"train\"):\n",
        "      \"\"\"\n",
        "      Save images and bounding boxes to respective directories of data subsets\n",
        "      \"\"\"\n",
        "      self._make_dir(f\"yolov5_data/labels/{choose_train_val}/\")\n",
        "      self._make_dir(f\"yolov5_data/images/{choose_train_val}/\")\n",
        "      for idx,row in enumerate(data.values):\n",
        "        filename = \"yolov5_data/labels/{}/{}\".format(choose_train_val,\n",
        "                                             (data['file_name'][idx]).split(\".\")[0]+\".txt\")\n",
        "        np.savetxt(filename,data[\"bbox\"][idx],\n",
        "                    fmt=[\"%d\",\"%f\",\"%f\",\"%f\",\"%f\"])\n",
        "        shutil.copyfile(os.path.join(\"/content/Data/trainval/images/\",data[\"file_name\"][idx]),\n",
        "                          os.path.join(f\"yolov5_data/images/{choose_train_val}/\",data[\"file_name\"][idx]))\n",
        "\n",
        "    def _main(self):\n",
        "      train_data, test_data = self._creating_data()\n",
        "      self._saving_images_labels(train_data)\n",
        "      self._saving_images_labels(test_data,choose_train_val=\"validation\")\n",
        "\n",
        "input = InputPipeline(input_file=\"/content/Data/trainval/annotations/bbox-annotations.json\")"
      ],
      "metadata": {
        "id": "Yycw2RBOalxD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip3 install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "bmsCCQOnn4ve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0fca45-23b5-42b9-d37e-db99c57b1c4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12875, done.\u001b[K\n",
            "remote: Total 12875 (delta 0), reused 0 (delta 0), pack-reused 12875\u001b[K\n",
            "Receiving objects: 100% (12875/12875), 11.84 MiB | 26.83 MiB/s, done.\n",
            "Resolving deltas: 100% (8947/8947), done.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 13)) (4.64.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 16)) (2.8.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 20)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 11)) (4.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 20)) (2022.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.2.0)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py --img 1024 --batch 16 --epochs 15 --data /content/yolo.yml --cfg /content/yolov5/models/yolov5s.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emdBKg4Lm_OR",
        "outputId": "6603c4f6-e82a-447e-9337-e231290a62f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolo.yml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=16, imgsz=1024, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.1-132-g014acde torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5/yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_data/labels/train.cache' images and labels... 2015 found, 0 missing, 0 empty, 0 corrupt: 100% 2015/2015 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_data/labels/validation.cache' images and labels... 224 found, 0 missing, 0 empty, 0 corrupt: 100% 224/224 [00:00<?, ?it/s]\n",
            "Plotting labels to yolov5/runs/train/exp4/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.50 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp4\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/14     7.73G    0.0859   0.08622   0.01672       257      1024: 100% 126/126 [05:51<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:09<00:00,  1.34s/it]\n",
            "                 all        224       1823      0.358      0.479      0.349      0.102\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/14     10.5G   0.06631   0.07328  0.007086       200      1024: 100% 126/126 [05:47<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:09<00:00,  1.30s/it]\n",
            "                 all        224       1823       0.53      0.485      0.481      0.153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/14     10.5G   0.05963   0.07563  0.006387       221      1024: 100% 126/126 [05:47<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.27s/it]\n",
            "                 all        224       1823      0.542      0.481      0.482      0.193\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/14     10.5G   0.05449   0.07613   0.00582       155      1024: 100% 126/126 [05:48<00:00,  2.77s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.26s/it]\n",
            "                 all        224       1823      0.653      0.595      0.631        0.3\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/14     10.5G   0.05004   0.07714  0.005338       201      1024: 100% 126/126 [05:48<00:00,  2.77s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.27s/it]\n",
            "                 all        224       1823      0.646       0.57      0.606      0.309\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/14     10.5G   0.04889   0.07607  0.004842       211      1024: 100% 126/126 [05:48<00:00,  2.77s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.28s/it]\n",
            "                 all        224       1823       0.72      0.577      0.639      0.326\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/14     10.5G   0.04714   0.07458  0.004752       241      1024: 100% 126/126 [05:48<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.26s/it]\n",
            "                 all        224       1823      0.678      0.617      0.645      0.335\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/14     10.5G   0.04648   0.07603  0.004403       160      1024: 100% 126/126 [05:48<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.26s/it]\n",
            "                 all        224       1823      0.709      0.603      0.647      0.337\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/14     10.5G   0.04497   0.07365  0.004219       218      1024: 100% 126/126 [05:48<00:00,  2.77s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.27s/it]\n",
            "                 all        224       1823      0.691      0.586      0.639      0.334\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/14     10.5G   0.04413   0.07096  0.004052       119      1024: 100% 126/126 [05:48<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.27s/it]\n",
            "                 all        224       1823      0.706      0.605      0.651      0.347\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/14     10.5G    0.0434   0.06883  0.003788       131      1024: 100% 126/126 [05:48<00:00,  2.77s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.26s/it]\n",
            "                 all        224       1823      0.687      0.622      0.657      0.351\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/14     10.5G   0.04288   0.06904  0.003516       222      1024: 100% 126/126 [05:48<00:00,  2.77s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.25s/it]\n",
            "                 all        224       1823      0.714      0.594      0.652      0.357\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/14     10.5G   0.04255   0.06853  0.003542       200      1024: 100% 126/126 [05:47<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.25s/it]\n",
            "                 all        224       1823      0.668      0.628      0.653      0.354\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/14     10.5G   0.04207   0.06838  0.003235       198      1024: 100% 126/126 [05:47<00:00,  2.76s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.25s/it]\n",
            "                 all        224       1823      0.698      0.617      0.651      0.356\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/14     10.5G   0.04108   0.06717  0.003184       256      1024: 100% 126/126 [05:49<00:00,  2.78s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.26s/it]\n",
            "                 all        224       1823      0.721      0.616      0.672      0.369\n",
            "\n",
            "15 epochs completed in 1.493 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp4/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from yolov5/runs/train/exp4/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating yolov5/runs/train/exp4/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:13<00:00,  1.96s/it]\n",
            "                 all        224       1823      0.721      0.616      0.671       0.37\n",
            "              person        224       1180      0.663      0.647      0.657      0.335\n",
            "                 car        224        643       0.78      0.584      0.686      0.404\n",
            "Results saved to \u001b[1myolov5/runs/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --source /content/yolov5_data/images/validation --weights /content/best.pt"
      ],
      "metadata": {
        "id": "xsTitqIMnwsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06559dbf-4031-4657-b61f-24d3cdf96fd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/best.pt'], source=/content/yolov5_data/images/validation, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-140-g3f3852e torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 224 layers, 7056607 parameters, 0 gradients\n",
            "image 1/224 /content/yolov5_data/images/validation/image_000000001.jpg: 480x640 1 person, 2 cars, Done. (0.405s)\n",
            "image 2/224 /content/yolov5_data/images/validation/image_000000004.jpg: 448x640 1 person, 1 car, Done. (0.320s)\n",
            "image 3/224 /content/yolov5_data/images/validation/image_000000022.jpg: 480x640 21 persons, 1 car, Done. (0.323s)\n",
            "image 4/224 /content/yolov5_data/images/validation/image_000000034.jpg: 448x640 25 persons, 10 cars, Done. (0.298s)\n",
            "image 5/224 /content/yolov5_data/images/validation/image_000000035.jpg: 384x640 10 persons, 5 cars, Done. (0.270s)\n",
            "image 6/224 /content/yolov5_data/images/validation/image_000000047.jpg: 448x640 1 person, 1 car, Done. (0.312s)\n",
            "image 7/224 /content/yolov5_data/images/validation/image_000000049.jpg: 480x640 1 person, 1 car, Done. (0.325s)\n",
            "image 8/224 /content/yolov5_data/images/validation/image_000000052.jpg: 384x640 5 persons, 5 cars, Done. (0.267s)\n",
            "image 9/224 /content/yolov5_data/images/validation/image_000000067.jpg: 640x480 7 persons, 4 cars, Done. (0.330s)\n",
            "image 10/224 /content/yolov5_data/images/validation/image_000000083.jpg: 448x640 1 person, 1 car, Done. (0.304s)\n",
            "image 11/224 /content/yolov5_data/images/validation/image_000000100.jpg: 480x640 1 person, 1 car, Done. (0.326s)\n",
            "image 12/224 /content/yolov5_data/images/validation/image_000000122.jpg: 448x640 4 persons, 4 cars, Done. (0.301s)\n",
            "image 13/224 /content/yolov5_data/images/validation/image_000000123.jpg: 480x640 15 persons, 2 cars, Done. (0.341s)\n",
            "image 14/224 /content/yolov5_data/images/validation/image_000000126.jpg: 448x640 7 persons, 2 cars, Done. (0.307s)\n",
            "image 15/224 /content/yolov5_data/images/validation/image_000000128.jpg: 448x640 31 persons, 2 cars, Done. (0.302s)\n",
            "image 16/224 /content/yolov5_data/images/validation/image_000000136.jpg: 448x640 12 persons, 4 cars, Done. (0.303s)\n",
            "image 17/224 /content/yolov5_data/images/validation/image_000000148.jpg: 480x640 3 persons, 2 cars, Done. (0.326s)\n",
            "image 18/224 /content/yolov5_data/images/validation/image_000000157.jpg: 448x640 11 persons, 4 cars, Done. (0.313s)\n",
            "image 19/224 /content/yolov5_data/images/validation/image_000000166.jpg: 544x640 1 person, 1 car, Done. (0.387s)\n",
            "image 20/224 /content/yolov5_data/images/validation/image_000000168.jpg: 480x640 4 persons, 3 cars, Done. (0.337s)\n",
            "image 21/224 /content/yolov5_data/images/validation/image_000000170.jpg: 480x640 1 person, 8 cars, Done. (0.356s)\n",
            "image 22/224 /content/yolov5_data/images/validation/image_000000181.jpg: 480x640 6 persons, 3 cars, Done. (0.337s)\n",
            "image 23/224 /content/yolov5_data/images/validation/image_000000184.jpg: 640x448 1 person, 3 cars, Done. (0.307s)\n",
            "image 24/224 /content/yolov5_data/images/validation/image_000000186.jpg: 448x640 6 persons, 2 cars, Done. (0.306s)\n",
            "image 25/224 /content/yolov5_data/images/validation/image_000000188.jpg: 416x640 8 persons, 1 car, Done. (0.293s)\n",
            "image 26/224 /content/yolov5_data/images/validation/image_000000196.jpg: 640x640 2 persons, 4 cars, Done. (0.438s)\n",
            "image 27/224 /content/yolov5_data/images/validation/image_000000202.jpg: 448x640 11 persons, 2 cars, Done. (0.296s)\n",
            "image 28/224 /content/yolov5_data/images/validation/image_000000215.jpg: 480x640 3 persons, 2 cars, Done. (0.318s)\n",
            "image 29/224 /content/yolov5_data/images/validation/image_000000216.jpg: 448x640 1 person, 1 car, Done. (0.320s)\n",
            "image 30/224 /content/yolov5_data/images/validation/image_000000231.jpg: 416x640 2 persons, 3 cars, Done. (0.308s)\n",
            "image 31/224 /content/yolov5_data/images/validation/image_000000245.jpg: 480x640 1 person, 1 car, Done. (0.328s)\n",
            "image 32/224 /content/yolov5_data/images/validation/image_000000248.jpg: 480x640 10 persons, 1 car, Done. (0.328s)\n",
            "image 33/224 /content/yolov5_data/images/validation/image_000000253.jpg: 448x640 12 persons, 1 car, Done. (0.320s)\n",
            "image 34/224 /content/yolov5_data/images/validation/image_000000266.jpg: 448x640 14 persons, 4 cars, Done. (0.306s)\n",
            "image 35/224 /content/yolov5_data/images/validation/image_000000276.jpg: 640x448 3 persons, 2 cars, Done. (0.313s)\n",
            "image 36/224 /content/yolov5_data/images/validation/image_000000292.jpg: 480x640 5 persons, 6 cars, Done. (0.330s)\n",
            "image 37/224 /content/yolov5_data/images/validation/image_000000305.jpg: 480x640 1 person, 2 cars, Done. (0.321s)\n",
            "image 38/224 /content/yolov5_data/images/validation/image_000000309.jpg: 448x640 6 persons, 5 cars, Done. (0.302s)\n",
            "image 39/224 /content/yolov5_data/images/validation/image_000000313.jpg: 640x448 8 persons, 2 cars, Done. (0.336s)\n",
            "image 40/224 /content/yolov5_data/images/validation/image_000000314.jpg: 448x640 2 persons, 1 car, Done. (0.310s)\n",
            "image 41/224 /content/yolov5_data/images/validation/image_000000318.jpg: 480x640 15 persons, 1 car, Done. (0.326s)\n",
            "image 42/224 /content/yolov5_data/images/validation/image_000000329.jpg: 256x640 7 persons, 4 cars, Done. (0.185s)\n",
            "image 43/224 /content/yolov5_data/images/validation/image_000000357.jpg: 480x640 1 person, 1 car, Done. (0.324s)\n",
            "image 44/224 /content/yolov5_data/images/validation/image_000000361.jpg: 480x640 43 persons, 7 cars, Done. (0.328s)\n",
            "image 45/224 /content/yolov5_data/images/validation/image_000000383.jpg: 448x640 2 persons, 2 cars, Done. (0.322s)\n",
            "image 46/224 /content/yolov5_data/images/validation/image_000000399.jpg: 448x640 2 persons, 1 car, Done. (0.303s)\n",
            "image 47/224 /content/yolov5_data/images/validation/image_000000422.jpg: 480x640 1 person, 2 cars, Done. (0.322s)\n",
            "image 48/224 /content/yolov5_data/images/validation/image_000000425.jpg: 640x512 4 persons, 3 cars, Done. (0.355s)\n",
            "image 49/224 /content/yolov5_data/images/validation/image_000000426.jpg: 480x640 13 persons, 1 car, Done. (0.319s)\n",
            "image 50/224 /content/yolov5_data/images/validation/image_000000437.jpg: 320x640 1 person, 1 car, Done. (0.218s)\n",
            "image 51/224 /content/yolov5_data/images/validation/image_000000453.jpg: 480x640 1 person, 2 cars, Done. (0.347s)\n",
            "image 52/224 /content/yolov5_data/images/validation/image_000000462.jpg: 480x640 19 persons, 2 cars, Done. (0.323s)\n",
            "image 53/224 /content/yolov5_data/images/validation/image_000000464.jpg: 480x640 2 persons, 1 car, Done. (0.320s)\n",
            "image 54/224 /content/yolov5_data/images/validation/image_000000468.jpg: 480x640 14 persons, 2 cars, Done. (0.320s)\n",
            "image 55/224 /content/yolov5_data/images/validation/image_000000484.jpg: 512x640 11 persons, 6 cars, Done. (0.361s)\n",
            "image 56/224 /content/yolov5_data/images/validation/image_000000497.jpg: 512x640 1 person, 3 cars, Done. (0.353s)\n",
            "image 57/224 /content/yolov5_data/images/validation/image_000000503.jpg: 640x480 2 persons, 4 cars, Done. (0.329s)\n",
            "image 58/224 /content/yolov5_data/images/validation/image_000000507.jpg: 416x640 9 persons, 4 cars, Done. (0.286s)\n",
            "image 59/224 /content/yolov5_data/images/validation/image_000000518.jpg: 384x640 4 persons, 5 cars, Done. (0.260s)\n",
            "image 60/224 /content/yolov5_data/images/validation/image_000000534.jpg: 480x640 1 person, 1 car, Done. (0.320s)\n",
            "image 61/224 /content/yolov5_data/images/validation/image_000000551.jpg: 480x640 4 persons, 1 car, Done. (0.322s)\n",
            "image 62/224 /content/yolov5_data/images/validation/image_000000566.jpg: 416x640 1 person, 3 cars, Done. (0.290s)\n",
            "image 63/224 /content/yolov5_data/images/validation/image_000000573.jpg: 480x640 3 persons, 2 cars, Done. (0.318s)\n",
            "image 64/224 /content/yolov5_data/images/validation/image_000000577.jpg: 480x640 2 persons, 1 car, Done. (0.320s)\n",
            "image 65/224 /content/yolov5_data/images/validation/image_000000582.jpg: 480x640 11 persons, 1 car, Done. (0.331s)\n",
            "image 66/224 /content/yolov5_data/images/validation/image_000000593.jpg: 480x640 3 persons, 6 cars, Done. (0.325s)\n",
            "image 67/224 /content/yolov5_data/images/validation/image_000000597.jpg: 384x640 1 person, 1 car, Done. (0.267s)\n",
            "image 68/224 /content/yolov5_data/images/validation/image_000000615.jpg: 448x640 2 persons, 1 car, Done. (0.354s)\n",
            "image 69/224 /content/yolov5_data/images/validation/image_000000628.jpg: 448x640 5 persons, 3 cars, Done. (0.298s)\n",
            "image 70/224 /content/yolov5_data/images/validation/image_000000669.jpg: 480x640 3 persons, 1 car, Done. (0.335s)\n",
            "image 71/224 /content/yolov5_data/images/validation/image_000000689.jpg: 640x480 5 persons, 1 car, Done. (0.338s)\n",
            "image 72/224 /content/yolov5_data/images/validation/image_000000696.jpg: 448x640 10 persons, 2 cars, Done. (0.311s)\n",
            "image 73/224 /content/yolov5_data/images/validation/image_000000700.jpg: 480x640 5 persons, 1 car, Done. (0.341s)\n",
            "image 74/224 /content/yolov5_data/images/validation/image_000000714.jpg: 448x640 2 persons, 1 car, Done. (0.323s)\n",
            "image 75/224 /content/yolov5_data/images/validation/image_000000717.jpg: 448x640 3 persons, 5 cars, Done. (0.315s)\n",
            "image 76/224 /content/yolov5_data/images/validation/image_000000729.jpg: 448x640 8 persons, 4 cars, Done. (0.310s)\n",
            "image 77/224 /content/yolov5_data/images/validation/image_000000736.jpg: 384x640 1 person, 1 car, Done. (0.267s)\n",
            "image 78/224 /content/yolov5_data/images/validation/image_000000749.jpg: 384x640 3 persons, 5 cars, Done. (0.266s)\n",
            "image 79/224 /content/yolov5_data/images/validation/image_000000761.jpg: 640x480 9 persons, 1 car, Done. (0.337s)\n",
            "image 80/224 /content/yolov5_data/images/validation/image_000000762.jpg: 480x640 3 persons, 2 cars, Done. (0.322s)\n",
            "image 81/224 /content/yolov5_data/images/validation/image_000000774.jpg: 480x640 2 persons, 1 car, Done. (0.348s)\n",
            "image 82/224 /content/yolov5_data/images/validation/image_000000784.jpg: 640x576 4 persons, 1 car, Done. (0.410s)\n",
            "image 83/224 /content/yolov5_data/images/validation/image_000000787.jpg: 640x480 12 persons, 4 cars, Done. (0.330s)\n",
            "image 84/224 /content/yolov5_data/images/validation/image_000000791.jpg: 448x640 11 persons, 2 cars, Done. (0.311s)\n",
            "image 85/224 /content/yolov5_data/images/validation/image_000000808.jpg: 480x640 10 persons, 5 cars, Done. (0.333s)\n",
            "image 86/224 /content/yolov5_data/images/validation/image_000000814.jpg: 448x640 6 persons, 5 cars, Done. (0.304s)\n",
            "image 87/224 /content/yolov5_data/images/validation/image_000000817.jpg: 448x640 3 persons, 1 car, Done. (0.300s)\n",
            "image 88/224 /content/yolov5_data/images/validation/image_000000840.jpg: 480x640 4 persons, 1 car, Done. (0.322s)\n",
            "image 89/224 /content/yolov5_data/images/validation/image_000000846.jpg: 448x640 1 person, 1 car, Done. (0.302s)\n",
            "image 90/224 /content/yolov5_data/images/validation/image_000000858.jpg: 448x640 1 person, 1 car, Done. (0.321s)\n",
            "image 91/224 /content/yolov5_data/images/validation/image_000000859.jpg: 384x640 2 persons, 3 cars, Done. (0.265s)\n",
            "image 92/224 /content/yolov5_data/images/validation/image_000000861.jpg: 640x480 1 person, 1 car, Done. (0.335s)\n",
            "image 93/224 /content/yolov5_data/images/validation/image_000000878.jpg: 416x640 2 persons, 3 cars, Done. (0.284s)\n",
            "image 94/224 /content/yolov5_data/images/validation/image_000000882.jpg: 448x640 3 persons, 1 car, Done. (0.308s)\n",
            "image 95/224 /content/yolov5_data/images/validation/image_000000885.jpg: 512x640 10 persons, 1 car, Done. (0.355s)\n",
            "image 96/224 /content/yolov5_data/images/validation/image_000000889.jpg: 640x448 1 person, 4 cars, Done. (0.324s)\n",
            "image 97/224 /content/yolov5_data/images/validation/image_000000905.jpg: 448x640 13 persons, 1 car, Done. (0.333s)\n",
            "image 98/224 /content/yolov5_data/images/validation/image_000000911.jpg: 640x480 7 persons, 4 cars, Done. (0.327s)\n",
            "image 99/224 /content/yolov5_data/images/validation/image_000000912.jpg: 448x640 5 persons, 2 cars, Done. (0.317s)\n",
            "image 100/224 /content/yolov5_data/images/validation/image_000000922.jpg: 480x640 2 persons, 1 car, Done. (0.330s)\n",
            "image 101/224 /content/yolov5_data/images/validation/image_000000923.jpg: 544x640 1 person, 1 car, Done. (0.376s)\n",
            "image 102/224 /content/yolov5_data/images/validation/image_000000925.jpg: 512x640 1 person, 1 car, Done. (0.374s)\n",
            "image 103/224 /content/yolov5_data/images/validation/image_000000928.jpg: 480x640 8 persons, Done. (0.334s)\n",
            "image 104/224 /content/yolov5_data/images/validation/image_000000940.jpg: 640x384 6 persons, 2 cars, Done. (0.285s)\n",
            "image 105/224 /content/yolov5_data/images/validation/image_000000947.jpg: 448x640 6 persons, 1 car, Done. (0.302s)\n",
            "image 106/224 /content/yolov5_data/images/validation/image_000000948.jpg: 448x640 2 persons, 6 cars, Done. (0.299s)\n",
            "image 107/224 /content/yolov5_data/images/validation/image_000000984.jpg: 448x640 3 persons, 3 cars, Done. (0.312s)\n",
            "image 108/224 /content/yolov5_data/images/validation/image_000001037.jpg: 448x640 6 persons, 4 cars, Done. (0.305s)\n",
            "image 109/224 /content/yolov5_data/images/validation/image_000001047.jpg: 640x480 1 person, 7 cars, Done. (0.337s)\n",
            "image 110/224 /content/yolov5_data/images/validation/image_000001064.jpg: 448x640 1 person, 1 car, Done. (0.323s)\n",
            "image 111/224 /content/yolov5_data/images/validation/image_000001086.jpg: 480x640 4 persons, 2 cars, Done. (0.341s)\n",
            "image 112/224 /content/yolov5_data/images/validation/image_000001098.jpg: 480x640 3 persons, 6 cars, Done. (0.330s)\n",
            "image 113/224 /content/yolov5_data/images/validation/image_000001100.jpg: 448x640 11 persons, 1 car, Done. (0.315s)\n",
            "image 114/224 /content/yolov5_data/images/validation/image_000001101.jpg: 640x448 8 persons, 2 cars, Done. (0.326s)\n",
            "image 115/224 /content/yolov5_data/images/validation/image_000001114.jpg: 448x640 19 persons, 6 cars, Done. (0.312s)\n",
            "image 116/224 /content/yolov5_data/images/validation/image_000001116.jpg: 480x640 3 persons, 2 cars, Done. (0.343s)\n",
            "image 117/224 /content/yolov5_data/images/validation/image_000001146.jpg: 448x640 5 persons, 7 cars, Done. (0.305s)\n",
            "image 118/224 /content/yolov5_data/images/validation/image_000001158.jpg: 640x512 6 persons, 5 cars, Done. (0.359s)\n",
            "image 119/224 /content/yolov5_data/images/validation/image_000001164.jpg: 448x640 1 person, 2 cars, Done. (0.315s)\n",
            "image 120/224 /content/yolov5_data/images/validation/image_000001168.jpg: 640x448 1 person, 1 car, Done. (0.307s)\n",
            "image 121/224 /content/yolov5_data/images/validation/image_000001189.jpg: 448x640 3 persons, 1 car, Done. (0.311s)\n",
            "image 122/224 /content/yolov5_data/images/validation/image_000001195.jpg: 640x512 5 persons, 1 car, Done. (0.362s)\n",
            "image 123/224 /content/yolov5_data/images/validation/image_000001209.jpg: 448x640 7 persons, 2 cars, Done. (0.301s)\n",
            "image 124/224 /content/yolov5_data/images/validation/image_000001211.jpg: 448x640 8 persons, 2 cars, Done. (0.308s)\n",
            "image 125/224 /content/yolov5_data/images/validation/image_000001215.jpg: 480x640 6 persons, 6 cars, Done. (0.316s)\n",
            "image 126/224 /content/yolov5_data/images/validation/image_000001216.jpg: 416x640 6 persons, 4 cars, Done. (0.282s)\n",
            "image 127/224 /content/yolov5_data/images/validation/image_000001228.jpg: 448x640 1 person, 4 cars, Done. (0.328s)\n",
            "image 128/224 /content/yolov5_data/images/validation/image_000001229.jpg: 384x640 3 persons, 2 cars, Done. (0.265s)\n",
            "image 129/224 /content/yolov5_data/images/validation/image_000001239.jpg: 544x640 3 persons, 1 car, Done. (0.370s)\n",
            "image 130/224 /content/yolov5_data/images/validation/image_000001246.jpg: 448x640 21 persons, 5 cars, Done. (0.316s)\n",
            "image 131/224 /content/yolov5_data/images/validation/image_000001272.jpg: 480x640 7 persons, 3 cars, Done. (0.334s)\n",
            "image 132/224 /content/yolov5_data/images/validation/image_000001277.jpg: 480x640 8 persons, 1 car, Done. (0.321s)\n",
            "image 133/224 /content/yolov5_data/images/validation/image_000001286.jpg: 480x640 1 person, 1 car, Done. (0.330s)\n",
            "image 134/224 /content/yolov5_data/images/validation/image_000001300.jpg: 416x640 6 persons, 4 cars, Done. (0.286s)\n",
            "image 135/224 /content/yolov5_data/images/validation/image_000001324.jpg: 480x640 1 person, 8 cars, Done. (0.328s)\n",
            "image 136/224 /content/yolov5_data/images/validation/image_000001335.jpg: 448x640 5 persons, 15 cars, Done. (0.318s)\n",
            "image 137/224 /content/yolov5_data/images/validation/image_000001338.jpg: 480x640 2 persons, 1 car, Done. (0.324s)\n",
            "image 138/224 /content/yolov5_data/images/validation/image_000001347.jpg: 448x640 1 person, 1 car, Done. (0.316s)\n",
            "image 139/224 /content/yolov5_data/images/validation/image_000001349.jpg: 480x640 7 persons, 1 car, Done. (0.323s)\n",
            "image 140/224 /content/yolov5_data/images/validation/image_000001352.jpg: 384x640 2 persons, 1 car, Done. (0.266s)\n",
            "image 141/224 /content/yolov5_data/images/validation/image_000001374.jpg: 480x640 1 person, 4 cars, Done. (0.338s)\n",
            "image 142/224 /content/yolov5_data/images/validation/image_000001387.jpg: 480x640 2 persons, 1 car, Done. (0.333s)\n",
            "image 143/224 /content/yolov5_data/images/validation/image_000001393.jpg: 352x640 18 persons, 4 cars, Done. (0.253s)\n",
            "image 144/224 /content/yolov5_data/images/validation/image_000001398.jpg: 512x640 3 persons, 8 cars, Done. (0.372s)\n",
            "image 145/224 /content/yolov5_data/images/validation/image_000001402.jpg: 480x640 4 persons, 1 car, Done. (0.329s)\n",
            "image 146/224 /content/yolov5_data/images/validation/image_000001442.jpg: 448x640 1 person, 4 cars, Done. (0.316s)\n",
            "image 147/224 /content/yolov5_data/images/validation/image_000001456.jpg: 480x640 12 persons, 3 cars, Done. (0.679s)\n",
            "image 148/224 /content/yolov5_data/images/validation/image_000001460.jpg: 480x640 2 persons, 7 cars, Done. (0.344s)\n",
            "image 149/224 /content/yolov5_data/images/validation/image_000001506.jpg: 480x640 2 persons, 2 cars, Done. (0.357s)\n",
            "image 150/224 /content/yolov5_data/images/validation/image_000001533.jpg: 640x640 1 person, 1 car, Done. (0.459s)\n",
            "image 151/224 /content/yolov5_data/images/validation/image_000001537.jpg: 640x448 1 person, 1 car, Done. (0.316s)\n",
            "image 152/224 /content/yolov5_data/images/validation/image_000001538.jpg: 480x640 1 person, 1 car, Done. (0.331s)\n",
            "image 153/224 /content/yolov5_data/images/validation/image_000001542.jpg: 448x640 2 persons, 2 cars, Done. (0.340s)\n",
            "image 154/224 /content/yolov5_data/images/validation/image_000001556.jpg: 448x640 17 persons, 1 car, Done. (0.336s)\n",
            "image 155/224 /content/yolov5_data/images/validation/image_000001558.jpg: 640x416 1 person, 4 cars, Done. (0.312s)\n",
            "image 156/224 /content/yolov5_data/images/validation/image_000001559.jpg: 352x640 8 persons, 3 cars, Done. (0.240s)\n",
            "image 157/224 /content/yolov5_data/images/validation/image_000001566.jpg: 512x640 1 person, 1 car, Done. (0.369s)\n",
            "image 158/224 /content/yolov5_data/images/validation/image_000001586.jpg: 448x640 2 persons, 3 cars, Done. (0.311s)\n",
            "image 159/224 /content/yolov5_data/images/validation/image_000001597.jpg: 640x480 1 person, 2 cars, Done. (0.334s)\n",
            "image 160/224 /content/yolov5_data/images/validation/image_000001621.jpg: 480x640 2 persons, 4 cars, Done. (0.335s)\n",
            "image 161/224 /content/yolov5_data/images/validation/image_000001627.jpg: 640x480 1 person, 6 cars, Done. (0.331s)\n",
            "image 162/224 /content/yolov5_data/images/validation/image_000001642.jpg: 480x640 1 person, 1 car, Done. (0.331s)\n",
            "image 163/224 /content/yolov5_data/images/validation/image_000001652.jpg: 384x640 9 persons, 1 car, Done. (0.277s)\n",
            "image 164/224 /content/yolov5_data/images/validation/image_000001656.jpg: 512x640 4 persons, 1 car, Done. (0.375s)\n",
            "image 165/224 /content/yolov5_data/images/validation/image_000001666.jpg: 448x640 5 persons, 6 cars, Done. (0.311s)\n",
            "image 166/224 /content/yolov5_data/images/validation/image_000001694.jpg: 640x512 4 persons, 4 cars, Done. (0.368s)\n",
            "image 167/224 /content/yolov5_data/images/validation/image_000001697.jpg: 480x640 10 persons, 1 car, Done. (0.338s)\n",
            "image 168/224 /content/yolov5_data/images/validation/image_000001702.jpg: 448x640 11 persons, 6 cars, Done. (0.318s)\n",
            "image 169/224 /content/yolov5_data/images/validation/image_000001719.jpg: 448x640 2 persons, 1 car, Done. (0.305s)\n",
            "image 170/224 /content/yolov5_data/images/validation/image_000001723.jpg: 384x640 1 person, 1 car, Done. (0.259s)\n",
            "image 171/224 /content/yolov5_data/images/validation/image_000001750.jpg: 384x640 1 person, 1 car, Done. (0.265s)\n",
            "image 172/224 /content/yolov5_data/images/validation/image_000001763.jpg: 448x640 8 persons, 1 car, Done. (0.352s)\n",
            "image 173/224 /content/yolov5_data/images/validation/image_000001766.jpg: 480x640 2 persons, 2 cars, Done. (0.326s)\n",
            "image 174/224 /content/yolov5_data/images/validation/image_000001792.jpg: 640x480 1 person, 4 cars, Done. (0.337s)\n",
            "image 175/224 /content/yolov5_data/images/validation/image_000001805.jpg: 448x640 3 persons, 1 car, Done. (0.306s)\n",
            "image 176/224 /content/yolov5_data/images/validation/image_000001807.jpg: 448x640 9 persons, 2 cars, Done. (0.312s)\n",
            "image 177/224 /content/yolov5_data/images/validation/image_000001811.jpg: 480x640 2 persons, 2 cars, Done. (0.343s)\n",
            "image 178/224 /content/yolov5_data/images/validation/image_000001825.jpg: 448x640 12 persons, 2 cars, Done. (0.306s)\n",
            "image 179/224 /content/yolov5_data/images/validation/image_000001826.jpg: 480x640 3 persons, 1 car, Done. (0.326s)\n",
            "image 180/224 /content/yolov5_data/images/validation/image_000001827.jpg: 640x448 5 persons, 1 car, Done. (0.307s)\n",
            "image 181/224 /content/yolov5_data/images/validation/image_000001838.jpg: 480x640 6 persons, 3 cars, Done. (0.332s)\n",
            "image 182/224 /content/yolov5_data/images/validation/image_000001847.jpg: 448x640 7 persons, 2 cars, Done. (0.335s)\n",
            "image 183/224 /content/yolov5_data/images/validation/image_000001872.jpg: 448x640 1 person, 2 cars, Done. (0.302s)\n",
            "image 184/224 /content/yolov5_data/images/validation/image_000001873.jpg: 480x640 7 persons, 4 cars, Done. (0.323s)\n",
            "image 185/224 /content/yolov5_data/images/validation/image_000001881.jpg: 640x480 1 person, 1 car, Done. (0.334s)\n",
            "image 186/224 /content/yolov5_data/images/validation/image_000001888.jpg: 480x640 5 persons, 4 cars, Done. (0.333s)\n",
            "image 187/224 /content/yolov5_data/images/validation/image_000001910.jpg: 448x640 5 persons, 6 cars, Done. (0.304s)\n",
            "image 188/224 /content/yolov5_data/images/validation/image_000001914.jpg: 480x640 9 persons, 2 cars, Done. (0.326s)\n",
            "image 189/224 /content/yolov5_data/images/validation/image_000001919.jpg: 512x640 3 persons, 4 cars, Done. (0.365s)\n",
            "image 190/224 /content/yolov5_data/images/validation/image_000001925.jpg: 448x640 11 persons, 1 car, Done. (0.307s)\n",
            "image 191/224 /content/yolov5_data/images/validation/image_000001927.jpg: 448x640 4 persons, 1 car, Done. (0.313s)\n",
            "image 192/224 /content/yolov5_data/images/validation/image_000001930.jpg: 480x640 1 person, 5 cars, Done. (0.325s)\n",
            "image 193/224 /content/yolov5_data/images/validation/image_000001936.jpg: 448x640 6 persons, 4 cars, Done. (0.301s)\n",
            "image 194/224 /content/yolov5_data/images/validation/image_000001942.jpg: 416x640 5 persons, 1 car, Done. (0.294s)\n",
            "image 195/224 /content/yolov5_data/images/validation/image_000001968.jpg: 448x640 1 person, 1 car, Done. (0.305s)\n",
            "image 196/224 /content/yolov5_data/images/validation/image_000001970.jpg: 480x640 18 persons, 1 car, Done. (0.327s)\n",
            "image 197/224 /content/yolov5_data/images/validation/image_000001972.jpg: 480x640 1 person, 1 car, Done. (0.343s)\n",
            "image 198/224 /content/yolov5_data/images/validation/image_000001976.jpg: 480x640 1 person, 7 cars, Done. (0.327s)\n",
            "image 199/224 /content/yolov5_data/images/validation/image_000001982.jpg: 288x640 1 person, 1 car, Done. (0.203s)\n",
            "image 200/224 /content/yolov5_data/images/validation/image_000001997.jpg: 448x640 3 persons, 1 car, Done. (0.310s)\n",
            "image 201/224 /content/yolov5_data/images/validation/image_000001999.jpg: 544x640 1 person, 1 car, Done. (0.382s)\n",
            "image 202/224 /content/yolov5_data/images/validation/image_000002034.jpg: 384x640 1 person, 1 car, Done. (0.267s)\n",
            "image 203/224 /content/yolov5_data/images/validation/image_000002036.jpg: 640x448 1 person, 1 car, Done. (0.315s)\n",
            "image 204/224 /content/yolov5_data/images/validation/image_000002058.jpg: 480x640 1 person, 1 car, Done. (0.351s)\n",
            "image 205/224 /content/yolov5_data/images/validation/image_000002060.jpg: 448x640 1 car, Done. (0.318s)\n",
            "image 206/224 /content/yolov5_data/images/validation/image_000002065.jpg: 448x640 9 persons, 6 cars, Done. (0.311s)\n",
            "image 207/224 /content/yolov5_data/images/validation/image_000002069.jpg: 480x640 3 persons, 4 cars, Done. (0.343s)\n",
            "image 208/224 /content/yolov5_data/images/validation/image_000002073.jpg: 480x640 3 persons, 1 car, Done. (0.337s)\n",
            "image 209/224 /content/yolov5_data/images/validation/image_000002084.jpg: 448x640 3 persons, 2 cars, Done. (0.325s)\n",
            "image 210/224 /content/yolov5_data/images/validation/image_000002096.jpg: 448x640 4 persons, 2 cars, Done. (0.318s)\n",
            "image 211/224 /content/yolov5_data/images/validation/image_000002102.jpg: 448x640 1 person, 2 cars, Done. (0.310s)\n",
            "image 212/224 /content/yolov5_data/images/validation/image_000002106.jpg: 448x640 5 persons, 6 cars, Done. (0.320s)\n",
            "image 213/224 /content/yolov5_data/images/validation/image_000002108.jpg: 448x640 5 persons, 2 cars, Done. (0.308s)\n",
            "image 214/224 /content/yolov5_data/images/validation/image_000002110.jpg: 480x640 1 person, 2 cars, Done. (0.318s)\n",
            "image 215/224 /content/yolov5_data/images/validation/image_000002129.jpg: 640x448 2 persons, 3 cars, Done. (0.320s)\n",
            "image 216/224 /content/yolov5_data/images/validation/image_000002132.jpg: 480x640 1 person, 6 cars, Done. (0.328s)\n",
            "image 217/224 /content/yolov5_data/images/validation/image_000002146.jpg: 480x640 1 person, 1 car, Done. (0.326s)\n",
            "image 218/224 /content/yolov5_data/images/validation/image_000002185.jpg: 448x640 5 persons, 4 cars, Done. (0.332s)\n",
            "image 219/224 /content/yolov5_data/images/validation/image_000002187.jpg: 448x640 9 persons, 1 car, Done. (0.306s)\n",
            "image 220/224 /content/yolov5_data/images/validation/image_000002196.jpg: 480x640 6 persons, 1 car, Done. (0.329s)\n",
            "image 221/224 /content/yolov5_data/images/validation/image_000002217.jpg: 448x640 1 person, 1 car, Done. (0.323s)\n",
            "image 222/224 /content/yolov5_data/images/validation/image_000002218.jpg: 640x448 2 persons, 3 cars, Done. (0.319s)\n",
            "image 223/224 /content/yolov5_data/images/validation/image_000002233.jpg: 448x640 1 person, 3 cars, Done. (0.307s)\n",
            "image 224/224 /content/yolov5_data/images/validation/image_000002237.jpg: 640x448 2 persons, Done. (0.316s)\n",
            "Speed: 1.6ms pre-process, 321.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/val.py --weights /content/best.pt --data /content/yolo.yml --img 640 --task speed"
      ],
      "metadata": {
        "id": "Y2XjMh29yiCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93760306-7588-45f1-b1c3-d2889601c140"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolo.yml, weights=['/content/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=speed, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-140-g3f3852e torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 224 layers, 7056607 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_data/labels/validation' images and labels...224 found, 0 missing, 0 empty, 0 corrupt: 100% 224/224 [00:00<00:00, 1330.56it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5_data/labels/validation.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [01:25<00:00, 12.18s/it]\n",
            "                 all        224       1750      0.915       0.82      0.895      0.603\n",
            "              person        224       1160      0.906      0.795      0.873      0.559\n",
            "                 car        224        590      0.925      0.844      0.918      0.647\n",
            "Speed: 4.4ms pre-process, 368.8ms inference, 0.6ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}